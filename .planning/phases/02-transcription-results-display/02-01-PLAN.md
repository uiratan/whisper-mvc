---
phase: 02-transcription-results-display
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/api/upload/route.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "Backend receives uploaded audio and invokes whisper.cpp binary"
    - "Audio is converted to WAV 16kHz mono format if needed"
    - "Transcription returns with word-level timestamps"
    - "Backend handles whisper.cpp errors gracefully"
  artifacts:
    - path: "src/app/api/upload/route.ts"
      provides: "Whisper.cpp integration with audio conversion and transcription parsing"
      min_lines: 150
      exports: ["POST"]
    - path: "package.json"
      provides: "Required dependencies for audio processing"
      contains: "fluent-ffmpeg"
  key_links:
    - from: "src/app/api/upload/route.ts"
      to: "whisper.cpp binary"
      via: "child_process.spawn"
      pattern: "spawn.*whisper"
    - from: "src/app/api/upload/route.ts"
      to: "ffmpeg conversion"
      via: "fluent-ffmpeg library"
      pattern: "ffmpeg.*audioCodec"
---

<objective>
Integrate whisper.cpp binary for audio transcription with automatic format conversion and structured output parsing.

Purpose: Enable backend to transcribe uploaded audio files using local whisper.cpp installation, handling format conversion when needed, and returning timestamped transcription results.

Output: Modified API endpoint that processes audio files through whisper.cpp and returns structured transcription data with timestamps.
</objective>

<execution_context>
@/home/uira/.claude/get-shit-done/workflows/execute-plan.md
@/home/uira/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@src/app/api/upload/route.ts

## From Phase 1

Phase 1 established:
- Upload endpoint at /api/upload that saves files to ./uploads directory
- File validation for .wav, .mp3, .ogg formats with 25MB max size
- Unique filename generation with timestamp prefix
- Files stored at path: ./uploads/{timestamp}-{sanitized-filename}

## Technical Context

**whisper.cpp binary**: Already compiled and available on user's machine (from PROJECT.md).

**Model selection**: Use tiny or base model for speed (from PROJECT.md constraints).

**Output format**: Need word-level timestamps, not just full transcript. Use whisper.cpp's JSON output format or SRT format for timestamp data.

**Audio requirements**: whisper.cpp requires WAV 16kHz mono format. Must convert other formats before processing.

**ffmpeg**: Standard tool for audio conversion, available via fluent-ffmpeg Node.js wrapper.

## Implementation Notes

whisper.cpp typical invocation:
```bash
./whisper.cpp -m models/ggml-base.bin -f input.wav --output-json
```

Common flags:
- `-m` or `--model`: Model file path
- `-f` or `--file`: Input audio file
- `--output-json`: JSON output with timestamps
- `--output-srt`: SRT subtitle format with timestamps

Audio conversion with ffmpeg:
- Input: Any audio format (.mp3, .ogg, .wav)
- Output: WAV, 16kHz sample rate, mono channel
- fluent-ffmpeg API: `.audioFrequency(16000).audioChannels(1).audioCodec('pcm_s16le')`
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install fluent-ffmpeg and add audio conversion utility</name>
  <files>
    package.json
    src/app/api/upload/route.ts
  </files>
  <action>
Install fluent-ffmpeg for audio format conversion:
```bash
npm install fluent-ffmpeg
npm install --save-dev @types/fluent-ffmpeg
```

Add audio conversion function to /api/upload route that converts any audio format to WAV 16kHz mono (whisper.cpp requirement):

```typescript
async function convertToWav(inputPath: string): Promise<string> {
  const outputPath = inputPath.replace(/\.[^.]+$/, '.wav')

  return new Promise((resolve, reject) => {
    ffmpeg(inputPath)
      .audioFrequency(16000)
      .audioChannels(1)
      .audioCodec('pcm_s16le')
      .toFormat('wav')
      .on('end', () => resolve(outputPath))
      .on('error', (err) => reject(err))
      .save(outputPath)
  })
}
```

Import ffmpeg at top of file:
```typescript
import ffmpeg from 'fluent-ffmpeg'
```

Place conversion function after the constant declarations, before the POST handler.

Use this function after saving the uploaded file, before calling whisper.cpp. Always convert to ensure consistent format regardless of input type.
  </action>
  <verify>
Run TypeScript compilation to verify types:
```bash
npx tsc --noEmit
```

Check package.json contains fluent-ffmpeg dependency:
```bash
grep "fluent-ffmpeg" package.json
```
  </verify>
  <done>
fluent-ffmpeg installed with TypeScript types, conversion function implemented that accepts any audio file path and returns promise resolving to converted WAV file path at 16kHz mono format.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement whisper.cpp transcription integration</name>
  <files>
    src/app/api/upload/route.ts
  </files>
  <action>
Add whisper.cpp transcription function using child_process.spawn to invoke the binary:

```typescript
import { spawn } from 'child_process'

interface TranscriptionSegment {
  start: number
  end: number
  text: string
}

interface TranscriptionResult {
  text: string
  segments: TranscriptionSegment[]
}

async function transcribeAudio(wavPath: string): Promise<TranscriptionResult> {
  return new Promise((resolve, reject) => {
    // Assume whisper.cpp binary is in PATH or at ./whisper.cpp
    // Try common locations: ./whisper.cpp, whisper.cpp (in PATH), ./main (whisper.cpp default binary name)
    const whisperBinary = process.env.WHISPER_CPP_PATH || 'whisper.cpp'

    // Use base model for balance of speed and accuracy (from PROJECT.md constraints)
    const modelPath = process.env.WHISPER_MODEL_PATH || 'models/ggml-base.bin'

    const args = [
      '-m', modelPath,
      '-f', wavPath,
      '--output-json',
      '--output-file', wavPath.replace('.wav', '')  // Output base path (whisper adds .json)
    ]

    const whisper = spawn(whisperBinary, args)

    let stderr = ''

    whisper.stderr.on('data', (data) => {
      stderr += data.toString()
      console.log(`[Whisper] ${data.toString().trim()}`)
    })

    whisper.on('close', async (code) => {
      if (code !== 0) {
        reject(new Error(`Whisper.cpp failed with code ${code}: ${stderr}`))
        return
      }

      // Read JSON output file
      const jsonPath = wavPath.replace('.wav', '.json')
      try {
        const jsonData = await readFile(jsonPath, 'utf-8')
        const result = JSON.parse(jsonData)

        // whisper.cpp JSON format has "transcription" array with segments
        const segments: TranscriptionSegment[] = result.transcription?.map((seg: any) => ({
          start: seg.offsets.from / 100, // Convert centiseconds to seconds
          end: seg.offsets.to / 100,
          text: seg.text.trim()
        })) || []

        const fullText = segments.map(s => s.text).join(' ')

        resolve({
          text: fullText,
          segments
        })
      } catch (err) {
        reject(new Error(`Failed to parse whisper.cpp output: ${err}`))
      }
    })

    whisper.on('error', (err) => {
      reject(new Error(`Failed to spawn whisper.cpp: ${err.message}`))
    })
  })
}
```

Add readFile import:
```typescript
import { readFile } from 'fs/promises'
```

Place transcribeAudio function after convertToWav, before POST handler.

Update POST handler to call these functions after saving the file:

```typescript
// After saving the uploaded file...
console.log(`[Upload API] File saved successfully: ${uniqueFilename}`)

// Convert to WAV format
console.log('[Upload API] Converting audio to WAV 16kHz mono...')
const wavPath = await convertToWav(filePath)
console.log(`[Upload API] Converted to: ${wavPath}`)

// Transcribe with whisper.cpp
console.log('[Upload API] Starting transcription...')
const transcription = await transcribeAudio(wavPath)
console.log('[Upload API] Transcription complete')

// Return success response with transcription
return NextResponse.json(
  {
    success: true,
    fileName: uniqueFilename,
    filePath: filePath,
    fileSize: file.size,
    message: 'File uploaded and transcribed successfully',
    transcription: transcription
  },
  { status: 200 }
)
```

Add transcription field to response type at top of file in UploadResponse interface if it exists in this file, or add to return type documentation.

Wrap the conversion and transcription calls in try/catch to handle errors:
- ffmpeg conversion errors: "Audio conversion failed"
- whisper.cpp spawn errors: "Transcription service unavailable"
- whisper.cpp execution errors: "Transcription failed"

Return appropriate error messages in 500 responses with descriptive messages for debugging.
  </action>
  <verify>
Run TypeScript compilation:
```bash
npx tsc --noEmit
```

Check that whisper.cpp integration code is present:
```bash
grep -n "spawn" src/app/api/upload/route.ts
grep -n "transcribeAudio" src/app/api/upload/route.ts
grep -n "convertToWav" src/app/api/upload/route.ts
```

Verify error handling is present:
```bash
grep -n "try.*catch" src/app/api/upload/route.ts
```
  </verify>
  <done>
POST endpoint modified to convert uploaded audio to WAV 16kHz mono, invoke whisper.cpp with base model, parse JSON output for transcription segments with timestamps, and return structured response including full text and timestamped segments. Error handling covers conversion failures, binary spawn errors, and transcription failures.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. TypeScript compilation passes without errors:
```bash
npx tsc --noEmit
```

2. Dependencies installed:
```bash
npm list fluent-ffmpeg
```

3. Code includes required functions:
- convertToWav function exists and returns Promise<string>
- transcribeAudio function exists and returns Promise<TranscriptionResult>
- POST handler calls both functions in sequence
- Error handling wraps async operations

4. Response structure includes transcription data:
- success: boolean
- transcription: { text: string, segments: Array<{start, end, text}> }
</verification>

<success_criteria>
1. API endpoint accepts audio file, converts to WAV 16kHz mono, and calls whisper.cpp binary
2. whisper.cpp invoked with base model via child_process.spawn
3. JSON output parsed and returned with transcription text and timestamped segments
4. Error handling returns descriptive messages for conversion or transcription failures
5. TypeScript types properly defined for transcription results
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-results-display/02-01-SUMMARY.md`
</output>
